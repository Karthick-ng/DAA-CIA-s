{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "846e038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from genetic_algorithm import GeneticAlgorithm\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(r\"C:\\Users\\Karthick NG\\Desktop\\KARTHICK\\SNU\\4TH SEMESTER\\1.ML\\1.ML LAB\\EX_9\\Bank_Personal_Loan_Modelling.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2584f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(['ID', 'ZIP Code', 'Personal Loan'], axis=1)\n",
    "y = data['Personal Loan']\n",
    "X = (X - X.mean()) / X.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "740a06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36325dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51e950b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class AntColonyOptimizer:\n",
    "    def __init__(self, model, X, y, ant_count, max_iter, q, alpha, beta, rho):\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.ant_count = ant_count\n",
    "        self.max_iter = max_iter\n",
    "        self.q = q\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "        self.tau = np.ones((self.X.shape[1],))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ab56d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _select_next_feature(self, feature_set, feature_probabilities):\n",
    "        # Select the next feature to add to the feature set\n",
    "        feature_idx = np.random.choice(np.arange(self.X.shape[1]), p=feature_probabilities)\n",
    "        feature_set.add(feature_idx)\n",
    "        # Update the pheromone trail for the selected feature\n",
    "        self.tau[feature_idx] *= (1 - self.rho)\n",
    "        self.tau[feature_idx] += self.rho * self.q\n",
    "        return feature_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "267ef4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the ACO optimizer\n",
    "# aco = AntColonyOptimizer(model, X_train, y_train, ant_count=10, max_iter=100, q=1, alpha=1, beta=2, rho=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20f3e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _calculate_probabilities(self, feature_set):\n",
    "        # Calculate the probabilities of selecting each feature not in the feature set\n",
    "        unselected_features = np.delete(np.arange(self.X.shape[1]), list(feature_set))\n",
    "        probabilities = np.zeros((len(unselected_features),))\n",
    "        tau_set = self.tau[list(feature_set)]\n",
    "        denominator = np.sum(tau_set * np.power(np.abs(self.X[:, unselected_features] - self.X[:, feature_set]), self.alpha) * np.power(np.abs(self.y - self.model.predict(self.X[:, feature_set]).ravel()), self.beta))\n",
    "        for i, feature_idx in enumerate(unselected_features):\n",
    "            numerator = self.tau[feature_idx] * np.power(np.abs(self.X[:, feature_idx] - self.X[:, feature_set]), self.alpha) * np.power(np.abs(self.y - self.model.predict(np.column_stack([self.X[:, list(feature_set)], self.X[:, feature_idx]])).ravel()), self.beta)\n",
    "            probabilities[i] = numerator / denominator\n",
    "        return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b09df085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def optimize_weights(self):\n",
    "        # Perform feature selection using ACO\n",
    "        best_feature_set = set()\n",
    "        best_loss = float('inf')\n",
    "        for iteration in range(self.max_iter):\n",
    "            feature_set = set()\n",
    "            feature_probabilities = np.ones((self.X.shape[1],))\n",
    "            while len(feature_set) < int(np.ceil(self.X.shape[1] * 0.5)):\n",
    "                # Select the next feature to add to the feature set\n",
    "                feature_idx = self._select_next_feature(feature_set, feature_probabilities)\n",
    "                # Update the probabilities based on the new feature\n",
    "                feature_probabilities = self._calculate_probabilities(feature_set)\n",
    "                feature_probabilities /= feature_probabilities.sum()  # normalize probabilities\n",
    "            # Train a model using the selected features and calculate the log loss\n",
    "            selected_features = sorted(list(feature_set))\n",
    "            self.model.fit(self.X[:, selected_features], self.y, epochs=10, batch_size=32, verbose=0)\n",
    "            loss = log_loss(self.y, self.model.predict(self.X[:, selected_features]))\n",
    "            # Update the best feature set if the log loss is lower\n",
    "            if loss < best_loss:\n",
    "                best_feature_set = feature_set\n",
    "                best_loss = loss\n",
    "        # Set the best weights to the model\n",
    "        selected_features = sorted(list(best_feature_set))\n",
    "        best_weights = self.model.get_weights()\n",
    "        for i, feature_idx in enumerate(selected_features):\n",
    "            best_weights[0][:, i] *= np.abs(self.X[:, feature_idx])\n",
    "        self.model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe193b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Optimize the weights using ACO\n",
    "# best_weights = aco.optimize_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d315b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Set the best weights to the model\n",
    "# model.set_weights(best_weights)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# accuracy = accuracy_score(y_test, model.predict(X_test).round())\n",
    "# print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "74c53074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class AntColonyOptimizer:\n",
    "#     def __init__(self, model, X_train, y_train, ant_count=10, max_iter=100, q=1, alpha=1, beta=2, rho=0.5):\n",
    "#         self.model = model\n",
    "#         self.X_train = X_train\n",
    "#         self.y_train = y_train\n",
    "#         self.ant_count = ant_count\n",
    "#         self.max_iter = max_iter\n",
    "#         self.q = q\n",
    "#         self.alpha = alpha\n",
    "#         self.beta = beta\n",
    "#         self.rho = rho\n",
    "#         self.pheromone = np.ones((X_train.shape[1],))\n",
    "#         self.best_weights = None\n",
    "#         self.best_accuracy = 0.0\n",
    "        \n",
    "#     def _compute_probabilities(self, weight_index, selected_features):\n",
    "#         unselected_features = np.setdiff1d(range(self.X_train.shape[1]), selected_features)\n",
    "#         numerators = (self.pheromone[weight_index, f]**self.alpha) * ((1 / self.model.evaluate(self.X_train[:, selected_features + [f]], self.y_train, verbose=0)[0])**self.beta)\n",
    "#         denominators = np.sum((self.pheromone[weight_index, unselected_features]**self.alpha) * ((1 / self.model.evaluate(self.X_train[:, selected_features + [f]], self.y_train, verbose=0)[0])**self.beta))\n",
    "#         probabilities = numerators / denominators\n",
    "#         return probabilities\n",
    "    \n",
    "#     def _generate_solution(self):\n",
    "#         selected_features = []\n",
    "#         for weight_index in range(self.X_train.shape[1]):\n",
    "#             probabilities = self._compute_probabilities(weight_index, selected_features)\n",
    "#             selected_feature = np.random.choice(range(self.X_train.shape[1]), p=probabilities)\n",
    "#             selected_features.append(selected_feature)\n",
    "#         return selected_features\n",
    "    \n",
    "\n",
    "\n",
    "#     def _evaluate_solution(self, selected_features):\n",
    "#         accuracy = accuracy_score(self.y_train, self.model.predict(self.X_train[:, selected_features]).round())\n",
    "#         if accuracy > self.best_accuracy:\n",
    "#             self.best_accuracy = accuracy\n",
    "#             self.best_weights = self.model.get_weights()\n",
    "#         return accuracy\n",
    "        \n",
    "#     def _update_pheromone(self):\n",
    "#         for i in range(self.ant_count):\n",
    "#             selected_features = self._generate_solution()\n",
    "#             accuracy = self._evaluate_solution(selected_features)\n",
    "#             for weight_index in range(self.X_train.shape[1]):\n",
    "#                 if weight_index in selected_features:\n",
    "#                     self.pheromone[weight_index] += self.q * accuracy\n",
    "#                 else:\n",
    "#                     self.pheromone[weight_index] *= (1 - self.rho)\n",
    "                    \n",
    "#     def optimize_weights(self):\n",
    "#         for i in range(self.max_iter):\n",
    "#             self._update_pheromone()\n",
    "#         self.model.set_weights(self.best_weights)\n",
    "#         return self.best_weights\n",
    "        \n",
    "\n",
    "# # Load data\n",
    "# X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=42)\n",
    "\n",
    "# # Split into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create the model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(10, input_dim=20, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
